什么是爬虫？
网络爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。

爬虫的工作流程
网络爬虫基本的工作流程是从一个根URL开始，抓取页面，解析页面中所有的URL，将还没有抓取过的URL放入工作队列中，之后继续抓取工作队列中的URL，重复抓取、解析，将解析到的url放入工作队列的步骤，直到工作队列为空为止。

线程池、回调、协程
我们希望通过并发执行来加快爬虫抓取页面的速度。一般的实现方式有三种：

线程池方式：开一个线程池，每当爬虫发现一个新链接，就将链接放入任务队列中，线程池中的线程从任务队列获取一个链接，之后建立socket，完成抓取页面、解析、将新连接放入工作队列的步骤。
def fetch(url):
    sock = socket.socket()
    sock.connect(('localhost.com', 3000))
    request = 'GET {} HTTP/1.0\r\nHost: localhost\r\n\r\n'.format(url)
    sock.send(request.encode('ascii'))
    response = b''
    chunk = sock.recv(4096)
    while chunk:
        response += chunk
        chunk = sock.recv(4096)

    links = parse_links(response)
    q.add(links)
默认的socket连接与读写是阻塞式的，在等待读入的这段时间的CPU占用是被完全浪费的。

回调方式：程序会有一个主循环叫做事件循环，在事件循环中会不断获得事件，通过在事件上注册解除回调函数来达到多任务并发执行的效果。缺点是一旦需要的回调操作变多，代码就会非常散，变得难以维护。
协程方式：同样通过事件循环执行程序，利用了Python 的生成器特性，生成器函数能够中途停止并在之后恢复，那么原本不得不分开写的回调函数就能够写在一个生成器函数中了，这也就实现了协程。
