神经元（Neurous）：神经网络的基本单元。神经元先获得输入，然后执行某些数学运算后，再产生一个输出。
先将输入乘以权重：
x1 -> x1 * w1
x2 -> x2 * w2
(x1*w1) + (x2*w2) + b

激活函数：将无限制的输入转换为可预测形式的输出。一种常用的激活函数是sigmoid函数：
sigmoid函数的输出介于0和1，我们可以理解为它把 (−∞,+∞) 范围内的数压缩到 (0, 1)以内。正值越大输出越接近1，负向数值越大输出越接近0。
例（sigmoid.py->Neuron）》》》偏值 w=[0, 1]; b=4; <=> w1=0, w2=1;  输入：x=[2, 3]
》》》以点积形式输出：w*x + b = (x1*w1) + (x2*w2) + b = 0*2 + 1*3 + 4 = 7
》》》sigmoid 函数输出：f(w*x + b) = f(7) = 0.999

---神经网络就是把一堆神经元连接在一起
1.把神经元的输入向前传递获得输出的过程称为前馈（feedforward）<=> 函数处理
2.现在把输出当做输入，由下个神经元处理，sigmoid->NeuralNetworks （有点像递归）

---训练神经网络（根据体重、身高推测性别）
Name       Weight(减去135斤)     Height(减去66inch)   Gender（男1）
Alice            -2                  -1               0
Bob              25                   6               1
Charlie          17                   4               1
Diana            -15                 -6               0
>>>1.定义好坏标准》》性别的均方误差MSE， 训练神经网络就是将损失最小化。
>>>2.优化算法，使损失最小。
随机梯度下降（SGD）：改变 权重 和 偏置
η：学习效率（leaming rate）：常数，决定训练网络速率快慢
>>>3.训练流程：
a.从数据集中选择一个样本；
b.计算损失函数对所有权重和偏置的偏导数；
c.使用更新公式更新每个权重和偏置；
d.回到第1步。
