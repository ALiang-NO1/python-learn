安卓agent：Mozilla/5.0 (Android5.1.1) AppleWebKit/537. 36 (KHTML, like Gecko) Chrome/41. 0.2225.0 Safari/537. 36
本机：{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) '
                    'Chrome/70.0.3538.25 Safari/537.36 Core/1.70.3775.400 QQBrowser/10.6.4209.400'}

百度爬取规定常使用的规范如下：

User-agent: * 这里的*代表的所有的搜索引擎种类，*是一个通配符。

Disallow: /baidu/ 这里定义是禁止爬寻baidu目录下面的目录。

Disallow: /dotcpp/*.htm 禁止访问/dotcpp/目录下的所有以".htm"为后缀的URL(包含子目录)。

Disallow: /*?* 禁止访问网站中所有包含问号 (?) 的网址。

Disallow: /.jpg$ 禁止抓取网页所有的.jpg格式的图片。

Disallow:/dotcpp/dotcpp.html 禁止爬取dotcpp文件夹下面的dotcpp.html文件。

Allow: /dotcpp/　这里定义是允许爬寻dotcpp目录下面的目录。

Allow: /dotcpp 这里定义是允许爬寻tmp的整个目录。

Allow: .htm$ 仅允许访问以".htm"为后缀的URL。

Allow: .gif$ 允许抓取网页和gif格式图片。

Sitemap: 网站地图，告诉爬虫这个页面是网站地图。

protocol :// hostname[:port] / path / [;parameters][?query]#fragment
URL由三部分组成，第一部分是协议，有http、https、ftp等，第二部分存放资源的服务器的域名或IP地址，第三部分为资源的具体地址。

 1. urllib模块
urllib是Python系统库中存在的一个模块，它提供了多个子模块：

1) urllib.request      提供打开和阅读URL的方法和类

2) urllib.error     包含异常类

3) urllib.parse     解析和引用URL

4) urllib.robotparser   解析robots.txt文件
我们使用最多的是第一个子模块中的方法，其中包含了对服务器请求的发出、跳转、代理等。

BeautifulSoup4的四个对象
BeautifulSoup把网页中的信息转换成一个复杂的树形结构，通过子树分解为四个对象，分别是Tag、NavigableSting、BeautifulSoup、Comment。
1) Tag
Tag与它的对应的汉语一个意思，对应的就是HTML中的标签，像我们在上面使用到的：
print(soup.title) # 获取title标签的名称
print(soup.a) # 获取所有的a标签中的所有内容
他们都属于标签信息，我们可以通过标签名来获取到这些标签中的内容，有一点需要注意的是在查找的时候，对应的是符合要求的第一个标签，
Tag有两个属性，分别是name和attrs，name也就是标签的名字，attrs对应class、id等信息。

2) NavigableSting
NavigableSting对应的是标签内部的文字，例如：
print(soup.title.string) # 获取标签的所有内容
通过这种方式就可以直接获取到标签内部的文字。

3) BeautifulSoup
BeautifulSoup对象对应的是文档中的内容，它类似于一个特殊的标签，我们可以获取到它的类型、名称和属性，也就是上面我们所使用到的：
soup = BeautifulSoup(html,"html.parser")

4) Comment
Comment对象是一个特殊的象，它输出的内容没有注释符号，如果不加以处理会影响我们对文档的解析，因为这种方式会忽略掉文档的注释，
因此注释中的内容会以代码格式被解析出来，进而影响我们的后续操作，所有我们 一般会采用.string来输出内容。

1. 遍历文档树
在解析文档文件的过程中，如果需要遍历文档，我们需要使用到一些特殊的方法，例如：

1) .contents    获取Tag的所有子节点，以列表的形式返回
例如：
con =  soup.head.contents
for i in con:
print(i)
先把tag的.content对象以列表的形式存储在con中，然后通过遍历来查看其中的元素。

2) .children
获取Tag的所有子节点，存储在一个生成器中，可以直接通过遍历的方式来访问，和上面例子一致。

3) .descendants     获取Tag的所有子孙节点。

4) .strings     获取子孙节点中的所有内容，可以通过遍历的方式来访问。

5) .parent      获取到Tag标签的父节点。

6) .parents     递归得到所有父辈节点，存放在一个生成器中，可以通过遍历的方式来访问。

7) .previous_siblings   获取Tag上面的所有兄弟节点，返回生成器。

8) .next_siblings   获取Tag下面的所有兄弟节点，返回生成器。

9) .has_attr    用于判断Tag是否包含属性。

2. 搜素文档树

我们在使用的过程中如果要匹配到搜索内容的全部信息，这时候就需要搜索整个文档树，我们需要采用到find_all方法，这个过滤器能贯穿整个搜索的AIP，
它可以使用在tag的name中，它的语法格式为：

find_all( name , attrs , recursive , text , **kwargs )
name参数即tag的名字，attrs为类或id，recursive为递归性，text为文本参数。

网页返回码含义：
100 继续。客户端应继续其请求
101 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议
200 请求成功。一般用于GET与POST请求
201 已创建。成功请求并创建了新的资源
202 已接受。已经接受请求，但未处理完成
203 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本
204 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档
205 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域
206 部分内容。服务器成功处理了部分GET请求
300 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择
301 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替
302 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI
303 查看其它地址。与301类似。使用GET和POST请求查看
304 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源
305 使用代理。所请求的资源必须通过代理访问
306 已经被废弃的HTTP状态码
307 临时重定向。与302类似。使用GET请求重定向
400 客户端请求的语法错误，服务器无法理解
401 请求要求用户的身份认证
402 保留，将来使用
403 服务器理解请求客户端的请求，但是拒绝执行此请求
404 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面
405 客户端请求中的方法被禁止
406 服务器无法根据客户端请求的内容特性完成请求
407 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权
408 服务器等待客户端发送的请求时间过长，超时
409 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突
410 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置
411 服务器无法处理客户端发送的不带Content-Length的请求信息
412 客户端请求信息的先决条件错误
413 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息
414 请求的URI过长（URI通常为网址），服务器无法处理
415 服务器无法处理请求附带的媒体格式
416 客户端请求的范围无效
417 服务器无法满足Expect的请求头信息
500 服务器内部错误，无法完成请求
501 服务器不支持请求的功能，无法完成请求
502 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求
503 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中
504 充当网关或代理的服务器，未及时从远端服务器获取请求
505 服务器不支持请求的HTTP协议的版本，无法完成处理

识别验证码使用模块：pillow  tesseract
安装：tesseract: https://github.com/tesseract-ocr/tesseract/releases/tag/5.0.0-alpha-20201231
如果报错：FileNotFoundError: 'tesseract', 修改 lib/sitepackages/pytesseract/pytesseract.py 中的21行 tesseract_cmd = 'tesseract安装目录'